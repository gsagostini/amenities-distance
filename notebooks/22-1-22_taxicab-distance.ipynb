{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b590d69-70e9-4547-a9fe-1b942e1d6de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "import osmnx as ox\n",
    "import taxicab.distance as tc\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8969bc16-ae7a-4a29-b423-f76bea24541c",
   "metadata": {},
   "source": [
    "# Network Distance in Taxicab Sense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc9c34e-0f2d-43ab-a8c0-058ed35c8ff3",
   "metadata": {},
   "source": [
    "In this notebook we try to collect the network distance of OD matrices using the taxicab package (https://github.com/nathanrooy/taxicab). Here, the amenities and centroids are mapped to the network's closest edge---not necessairily the closest node. I wrap the function to parallelize it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f3bb01-f081-4c01-a89c-751110fc4507",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shortest_path_taxicab_distance(G, origin_yx, destination_yx):\n",
    "    return tc.shortest_path(G, origin_yx, destination_yx)[0]\n",
    "\n",
    "def parallel_shortest_path_taxicab_distance(G, origin_yx_list, destination_yx_list, cpus):\n",
    "    \n",
    "    args = ((G, origin, destination) for origin, destination in zip(origin_yx_list, destination_yx_list))\n",
    "    pool = Pool(cpus)\n",
    "    sma = pool.starmap_async(shortest_path_taxicab_distance, args)\n",
    "    outputs = sma.get()\n",
    "\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a399c1-b704-40b7-b514-20cb38601087",
   "metadata": {},
   "source": [
    "The following functions do our algorithm to compute distances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a025b8-448c-4c5d-bec3-194cf1c0387d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fua_buffered_shapefile_dir = '../data/d03_intermediate/FUA-buffered-shapefile/'\n",
    "full_od_matrix_dir = '../data/d02_processed-safegraph/'\n",
    "networks_dir = '../data/d03_intermediate/FUA-networks/'\n",
    "\n",
    "def get_boundary(fua_code):\n",
    "    return gpd.read_file(fua_buffered_shapefile_dir + 'FUA-buffered.shp').set_index('fuacode').loc[[fua_code]]\n",
    "\n",
    "def get_fua_ODmatrix(fua_code):\n",
    "    full_od_matrix = pd.read_csv(full_od_matrix_dir + 'weeks_od_us_fua.csv', nrows=1000)\n",
    "    fua_raw_od_matrix = full_od_matrix[full_od_matrix.fuacode==fua_code][:10].reset_index(drop=True)\n",
    "    fua_raw_od_matrix['fuacode'] = fua_code\n",
    "    \n",
    "    return fua_raw_od_matrix\n",
    "\n",
    "def load_graphs(fua_code, proj_crs='EPSG:5070'):\n",
    "    walk_graph = ox.project_graph(ox.load_graphml(networks_dir + 'walk/'+fua_code+'.graphml'), to_crs=proj_crs)\n",
    "    drive_graph = ox.project_graph(ox.load_graphml(networks_dir + 'drive/'+fua_code+'.graphml'), to_crs=proj_crs)\n",
    "    \n",
    "    return walk_graph, drive_graph\n",
    "\n",
    "def trim_centroids(od_matrix, buffered_boundary, bdry_as_gdf=True):\n",
    "    \n",
    "    if bdry_as_gdf:\n",
    "        buffered_boundary = buffered_boundary.geometry[0]\n",
    "    \n",
    "    centroids_pt = gpd.points_from_xy(x= od_matrix.intptlon, y=od_matrix.intptlat, crs='EPSG:4326')\n",
    "    rows_to_keep = centroids_pt.within(buffered_boundary)\n",
    "    trimmed_od_matrix = od_matrix[rows_to_keep].reset_index(drop=True)\n",
    "    \n",
    "    print('.   total of', len(trimmed_od_matrix), ' rows')\n",
    "\n",
    "    return trimmed_od_matrix\n",
    "\n",
    "def add_od_geometries(od_matrix, proj_crs='EPSG:5070'):\n",
    "    centroids_pt = gpd.points_from_xy(x=od_matrix.intptlon, y=od_matrix.intptlat, crs='EPSG:4326').to_crs(proj_crs)\n",
    "    od_matrix['origin_x'], od_matrix['origin_y'] = centroids_pt.x, centroids_pt.y\n",
    "\n",
    "    places_pt = gpd.points_from_xy(x= od_matrix.longitude, y=od_matrix.latitude, crs='EPSG:4326').to_crs(proj_crs)\n",
    "    od_matrix['dest_x'], od_matrix['dest_y'] = places_pt.x, places_pt.y\n",
    "    \n",
    "    return od_matrix\n",
    "\n",
    "def add_preferred_mode(od_matrix, max_walk_dist=2000, proj_crs='EPSG:5070'):\n",
    "    \n",
    "    places_pt = gpd.points_from_xy(x= od_matrix.longitude, y=od_matrix.latitude, crs='EPSG:4326').to_crs(proj_crs)\n",
    "    centroids_pt = gpd.points_from_xy(x=od_matrix.intptlon, y=od_matrix.intptlat, crs='EPSG:4326').to_crs(proj_crs)\n",
    "    \n",
    "    od_matrix['mode'] = places_pt.distance(centroids_pt) <= max_walk_dist\n",
    "    od_matrix['mode'] = od_matrix['mode'].map({True: 'walk', False:'drive'})\n",
    "    \n",
    "    return od_matrix\n",
    "    \n",
    "def add_distances(od_matrix, walk_graph, drive_graph, cpus=1):\n",
    "    \n",
    "    #Split the dataframe in two according to commute mode:\n",
    "    od_matrix_dict = {mode: df for mode, df in od_matrix.groupby('mode')}\n",
    "    G = {'drive': drive_graph, 'walk': walk_graph}\n",
    "    \n",
    "    #For each of the commute modes, do the distance computation:\n",
    "    full_dfs = []\n",
    "    for mode, df in od_matrix_dict.items():\n",
    "        df['distance'] = parallel_shortest_path_taxicab_distance(G[mode],\n",
    "                                                                 zip(df['origin_y'].values, df['origin_x'].values),\n",
    "                                                                 zip(df['dest_y'].values, df['dest_x'].values),\n",
    "                                                                 cpus)\n",
    "        full_dfs.append(df)    \n",
    "    \n",
    "    #Merge the two dataframes:\n",
    "    od_matrix_naivedistance = pd.concat(full_dfs, ignore_index=True)\n",
    "    \n",
    "    return od_matrix_naivedistance\n",
    "\n",
    "def refine_distances(od_matrix_with_distances, drive_graph, max_walk_dist=2000, cpus=1):\n",
    "    \n",
    "    rows_to_repeat = (od_matrix_with_distances['mode']=='walk') & (od_matrix_with_distances['distance'] > max_walk_dist)\n",
    "    df_to_repeat = od_matrix_with_distances[rows_to_repeat]\n",
    "    \n",
    "    print('.   repeat for', len(df_to_repeat), ' rows')\n",
    "    \n",
    "    if len(df_to_repeat) > 0:\n",
    "        origin_yx = zip(df_to_repeat['origin_y'].values, df_to_repeat['origin_x'].values)\n",
    "        dest_yx = zip(df_to_repeat['dest_y'].values, df_to_repeat['dest_x'].values)\n",
    "\n",
    "        od_matrix_with_distances.loc[rows_to_repeat, 'distance'] = parallel_shortest_path_taxicab_distance(drive_graph,\n",
    "                                                                                                           origin_yx, dest_yx,\n",
    "                                                                                                           cpus)\n",
    "    \n",
    "    return od_matrix_with_distances\n",
    "\n",
    "def drop_cols(od_matrix, cols_to_drop=['origin_x', 'origin_y', 'dest_x', 'dest_y']):\n",
    "    \n",
    "    for col in od_matrix_naivedistance.columns:\n",
    "        if 'Unnamed' in col:\n",
    "            cols_to_drop.append(col)\n",
    "            \n",
    "    final_matrix = od_matrix.drop(cols_to_drop, axis=1).reset_index(drop=True)\n",
    "    \n",
    "    return final_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c9a3e0-7494-46ca-ae33-d3317b57ad16",
   "metadata": {},
   "source": [
    "Let's test it for a few rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d59972-09f4-4bbb-863f-ebd28e4f8a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold=2000\n",
    "number_of_cores=2\n",
    "fua_code='USA80'\n",
    "\n",
    "start=datetime.now()\n",
    "\n",
    "#1. LOAD ALL THE FILES:\n",
    "fua_buffered_boundary = get_boundary(fua_code) #get the FUA boundary\n",
    "fua_raw_od_matrix = get_fua_ODmatrix(fua_code) #get the commutes within that FUA\n",
    "walk_graph, drive_graph = load_graphs(fua_code) #get the graphs\n",
    "\n",
    "loading_complete=datetime.now()\n",
    "print('Loaded all files in:', loading_complete-start)\n",
    "\n",
    "#2. PREPROCESS THE MATRIX:\n",
    "fua_od_matrix = trim_centroids(fua_raw_od_matrix, fua_buffered_boundary)\n",
    "georeferenced_fua_od_matrix = add_od_geometries(fua_od_matrix)\n",
    "georeferenced_fua_od_matrix_with_mode = add_preferred_mode(georeferenced_fua_od_matrix, threshold)\n",
    "\n",
    "processing_complete=datetime.now()\n",
    "print('Prepared matrix in:', processing_complete-loading_complete)\n",
    "\n",
    "#3. OBTAIN THE DISTANCES:\n",
    "matrix_naive_distances = add_distances(georeferenced_fua_od_matrix_with_mode, walk_graph, drive_graph, cpus=number_of_cores)\n",
    "\n",
    "distances_complete=datetime.now()\n",
    "print('Obtained distances in:', distances_complete-processing_complete)\n",
    "\n",
    "#4. REPEAT FOR EDGE CASES:\n",
    "matrix_final_distances = refine_distances(matrix_naive_distances, drive_graph, threshold, cpus=number_of_cores)\n",
    "\n",
    "all_complete=datetime.now()\n",
    "print('Refined distances in:', all_complete-distances_complete)\n",
    "\n",
    "#5. WRAP-UP MATRIX AND SAVE IT:\n",
    "final_matrix = drop_cols(matrix_final_distances)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
