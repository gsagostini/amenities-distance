{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b590d69-70e9-4547-a9fe-1b942e1d6de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8969bc16-ae7a-4a29-b423-f76bea24541c",
   "metadata": {},
   "source": [
    "# Snapping POIs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc9c34e-0f2d-43ab-a8c0-058ed35c8ff3",
   "metadata": {},
   "source": [
    "Following the approach proposed in [this blog post](https://towardsdatascience.com/connecting-pois-to-a-road-network-358a81447944) by Yuwen Chang, we can attach the POIs and centroids to the street networks as new nodes. The modified code is available in the src directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "56f3bb01-f081-4c01-a89c-751110fc4507",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import osmnx as ox\n",
    "\n",
    "import rtree\n",
    "import itertools\n",
    "\n",
    "from shapely.geometry import MultiPoint, LineString\n",
    "from shapely.ops import snap, split\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "# Source code at https://github.com/ywnch/toolbox/blob/master/toolbox.py\n",
    "# Yuwen Chang\n",
    "# 2020-08-16\n",
    "\n",
    "def connect_poi(pois, nodes, edges, key_col='numerical_id', path=None, threshold=200, knn=5, meter_epsg=5070):\n",
    "    \"\"\"Connect and integrate a set of POIs into an existing road network.\n",
    "    Given a road network in the form of two GeoDataFrames: nodes and edges,\n",
    "    link each POI to the nearest edge (road segment) based on its projection\n",
    "    point (PP) and generate a new integrated road network including the POIs,\n",
    "    the projected points, and the connection edge.\n",
    "    Args:\n",
    "        pois (GeoDataFrame): a gdf of POI (geom: Point)\n",
    "        nodes (GeoDataFrame): a gdf of road network nodes (geom: Point)\n",
    "        edges (GeoDataFrame): a gdf of road network edges (geom: LineString)\n",
    "        key_col (str): a unique key column of pois should be provided,\n",
    "                       e.g., 'index', 'osmid', 'poi_number', etc.\n",
    "                       Currently, this will be renamed into 'osmid' in the output.\n",
    "                       [NOTE] For use in pandana, you may want to ensure this\n",
    "                              column is numeric-only to avoid processing errors.\n",
    "                              Preferably use unique integers (int or str) only,\n",
    "                              and be aware not to intersect with the node key,\n",
    "                              'osmid' if you use OSM data, in the nodes gdf.\n",
    "        path (str): directory path to use for saving files (nodes and edges).\n",
    "                      Outputs will NOT be saved if this arg is not specified.\n",
    "        threshold (int): the max length of a POI connection edge, POIs with\n",
    "                         connection edge beyond this length will be removed.\n",
    "                         The unit is in meters as crs epsg is set to 3857 by\n",
    "                         default during processing.\n",
    "        knn (int): k nearest neighbors to query for the nearest edge.\n",
    "                   Consider increasing this number up to 10 if the connection\n",
    "                   output is slightly unreasonable. But higher knn number will\n",
    "                   slow down the process.\n",
    "        meter_epsg (int): preferred EPSG in meter units. Suggested 3857 or 3395.\n",
    "    Returns:\n",
    "        nodes (GeoDataFrame): the original gdf with POIs and PPs appended\n",
    "        edges (GeoDataFrame): the original gdf with connection edges appended\n",
    "                              and existing edges updated (if PPs are present)\n",
    "    Note:\n",
    "        1. Make sure all three input GeoDataFrames have defined crs attribute.\n",
    "           Try something like `gdf.crs` or `gdf.crs = 'epsg:4326'`.\n",
    "           They will then be converted into epsg:3857 or specified meter_epsg for processing.\n",
    "    \"\"\"\n",
    "\n",
    "    ## STAGE 0: initialization\n",
    "    # 0-1: helper functions\n",
    "    def find_kne(point, lines):\n",
    "        dists = np.array(list(map(lambda l: l.distance(point), lines)))\n",
    "        kne_pos = dists.argsort()[0]\n",
    "        kne = lines.iloc[[kne_pos]]\n",
    "        kne_idx = kne.index[0]\n",
    "        return kne_idx, kne.values[0]\n",
    "\n",
    "    def get_pp(point, line):\n",
    "        \"\"\"Get the projected point (pp) of 'point' on 'line'.\"\"\"\n",
    "        # project new Point to be interpolated\n",
    "        pp = line.interpolate(line.project(point))  # PP as a Point\n",
    "        return pp\n",
    "\n",
    "    def split_line(line, pps):\n",
    "        \"\"\"Split 'line' by all intersecting 'pps' (as multipoint).\n",
    "        Returns:\n",
    "            new_lines (list): a list of all line segments after the split\n",
    "        \"\"\"\n",
    "        # IMPORTANT FIX for ensuring intersection between splitters and the line\n",
    "        # but no need for updating edges_meter manually because the old lines will be\n",
    "        # replaced anyway\n",
    "        line = snap(line, pps, 1e-8)  # slow?\n",
    "\n",
    "        try:\n",
    "            new_lines = list(split(line, pps))  # split into segments\n",
    "            return new_lines\n",
    "        except TypeError as e:\n",
    "            print('Error when splitting line: {}\\n{}\\n{}\\n'.format(e, line, pps))\n",
    "            return []\n",
    "\n",
    "    def update_nodes(nodes, new_points, ptype, meter_epsg=3857):\n",
    "        \"\"\"Update nodes with a list (pp) or a GeoDataFrame (poi) of new_points.\n",
    "        \n",
    "        Args:\n",
    "            ptype: type of Point list to append, 'pp' or 'poi'\n",
    "        \"\"\"\n",
    "        # create gdf of new nodes (projected PAPs)\n",
    "        if ptype == 'pp':\n",
    "            new_nodes = gpd.GeoDataFrame(new_points, columns=['geometry'], crs=f'epsg:{meter_epsg}')\n",
    "            n = len(new_nodes)\n",
    "            new_nodes['highway'] = node_highway_pp\n",
    "            new_nodes['osmid'] = [int(osmid_prefix + i) for i in range(n)]\n",
    "\n",
    "        # create gdf of new nodes (original POIs)\n",
    "        elif ptype == 'poi':\n",
    "            new_nodes = new_points[['geometry', key_col]]\n",
    "            new_nodes.columns = ['geometry', 'osmid']\n",
    "            new_nodes['highway'] = node_highway_poi\n",
    "            new_nodes['osmid'] = new_nodes['osmid'].astype(int)\n",
    "\n",
    "        else:\n",
    "            print(\"Unknown ptype when updating nodes.\")\n",
    "\n",
    "        # merge new nodes (it is safe to ignore the index for nodes)\n",
    "        gdfs = [nodes, new_nodes]\n",
    "        nodes = gpd.GeoDataFrame(pd.concat(gdfs, ignore_index=True, sort=False),\n",
    "                                 crs=gdfs[0].crs)\n",
    "\n",
    "        return nodes, new_nodes  # all nodes, newly added nodes only\n",
    "\n",
    "    def update_edges(edges, new_lines, replace):\n",
    "        \"\"\"\n",
    "        Update edge info by adding new_lines; or,\n",
    "        replace existing ones with new_lines (n-split segments).\n",
    "        Args:\n",
    "            replace: treat new_lines (flat list) as newly added edges if False,\n",
    "                     else replace existing edges with new_lines (often a nested list)\n",
    "        \n",
    "        Note:\n",
    "            kne_idx refers to 'fid in Rtree'/'label'/'loc', not positional iloc\n",
    "        \"\"\"\n",
    "        # for interpolation (split by pp): replicate old line\n",
    "        if replace:\n",
    "            # create a flattened gdf with all line segs and corresponding kne_idx\n",
    "            kne_idxs = list(line_pps_dict.keys())\n",
    "            lens = [len(item) for item in new_lines]\n",
    "            new_lines_gdf = gpd.GeoDataFrame(\n",
    "                {'kne_idx': np.repeat(kne_idxs, lens),\n",
    "                 'geometry': list(itertools.chain.from_iterable(new_lines))})\n",
    "            # merge to inherit the data of the replaced line\n",
    "            cols = list(edges.columns)\n",
    "            cols.remove('geometry')  # don't include the old geometry\n",
    "            new_edges = new_lines_gdf.merge(edges[cols], how='left', left_on='kne_idx', right_index=True)\n",
    "            new_edges.drop('kne_idx', axis=1, inplace=True)\n",
    "            new_lines = new_edges['geometry']  # now a flatten list\n",
    "        # for connection (to external poi): append new lines\n",
    "        else:\n",
    "            new_edges = gpd.GeoDataFrame(pois[[key_col]], geometry=new_lines, columns=[key_col, 'geometry'])\n",
    "            new_edges['oneway'] = False\n",
    "            new_edges['highway'] = edge_highway\n",
    "\n",
    "        # update features (a bit slow)\n",
    "        new_edges['length'] = [l.length for l in new_lines]\n",
    "        new_edges['from'] = new_edges['geometry'].map(\n",
    "            lambda x: nodes_id_dict.get(list(x.coords)[0], None))\n",
    "        new_edges['to'] = new_edges['geometry'].map(\n",
    "            lambda x: nodes_id_dict.get(list(x.coords)[-1], None))\n",
    "        new_edges['osmid'] = ['_'.join(list(map(str, s))) for s in zip(new_edges['from'], new_edges['to'])]\n",
    "\n",
    "        # remember to reindex to prevent duplication when concat\n",
    "        start = edges.index[-1] + 1\n",
    "        stop = start + len(new_edges)\n",
    "        new_edges.index = range(start, stop)\n",
    "\n",
    "        # for interpolation: remove existing edges\n",
    "        if replace:\n",
    "            edges = edges.drop(kne_idxs, axis=0)\n",
    "        # for connection: filter invalid links\n",
    "        else:\n",
    "            valid_pos = np.where(new_edges['length'] <= threshold)[0]\n",
    "            n = len(new_edges)\n",
    "            n_fault = n - len(valid_pos)\n",
    "            f_pct = n_fault / n * 100\n",
    "            print(\"Remove faulty projections: {}/{} ({:.2f}%)\".format(n_fault, n, f_pct))\n",
    "            new_edges = new_edges.iloc[valid_pos]  # use 'iloc' here\n",
    "\n",
    "        # merge new edges\n",
    "        dfs = [edges, new_edges]\n",
    "        edges = gpd.GeoDataFrame(pd.concat(dfs, ignore_index=False, sort=False), crs=dfs[0].crs)\n",
    "\n",
    "        # all edges, newly added edges only\n",
    "        return edges, new_edges\n",
    "\n",
    "    # 0-2: configurations\n",
    "    # set poi arguments\n",
    "    node_highway_pp = 'projected_pap'  # POI Access Point\n",
    "    node_highway_poi = 'poi'\n",
    "    edge_highway = 'projected_footway'\n",
    "    osmid_prefix = 9990000000\n",
    "\n",
    "    # convert CRS\n",
    "    pois_meter = pois.to_crs(epsg=meter_epsg)\n",
    "    nodes_meter = nodes.to_crs(epsg=meter_epsg)\n",
    "    edges_meter = edges.to_crs(epsg=meter_epsg)\n",
    "\n",
    "    # build rtree\n",
    "    print(\"Building rtree...\")\n",
    "    Rtree = rtree.index.Index()\n",
    "    [Rtree.insert(fid, geom.bounds) for fid, geom in edges_meter['geometry'].iteritems()]\n",
    "\n",
    "    ## STAGE 1: interpolation\n",
    "    # 1-1: update external nodes (pois)\n",
    "    print(\"Updating external nodes...\")\n",
    "    nodes_meter, _ = update_nodes(nodes_meter, pois_meter, ptype='poi', meter_epsg=meter_epsg)\n",
    "\n",
    "    # 1-2: update internal nodes (interpolated pps)\n",
    "    # locate nearest edge (kne) and projected point (pp)\n",
    "    print(\"Projecting POIs to the network...\")\n",
    "    pois_meter['near_idx'] = [list(Rtree.nearest(point.bounds, knn))\n",
    "                              for point in pois_meter['geometry']]  # slow\n",
    "    \n",
    "    pois_meter['near_lines'] = [edges_meter['geometry'][near_idx]\n",
    "                                for near_idx in pois_meter['near_idx']]  # very slow\n",
    "    pois_meter['kne_idx'], knes = zip(\n",
    "        *[find_kne(point, near_lines) for point, near_lines in\n",
    "          zip(pois_meter['geometry'], pois_meter['near_lines'])])  # slow\n",
    "    pois_meter['pp'] = [get_pp(point, kne) for point, kne in zip(pois_meter['geometry'], knes)]\n",
    "\n",
    "    # update nodes\n",
    "    print(\"Updating internal nodes...\")\n",
    "    nodes_meter, _ = update_nodes(nodes_meter, list(pois_meter['pp']), ptype='pp', meter_epsg=meter_epsg)\n",
    "    nodes_coord = nodes_meter['geometry'].map(lambda x: x.coords[0])\n",
    "    nodes_id_dict = dict(zip(nodes_coord, nodes_meter['osmid'].astype('Int64')))\n",
    "\n",
    "    # 1-3: update internal edges (split line segments)\n",
    "    print(\"Updating internal edges...\")\n",
    "    # split\n",
    "    line_pps_dict = {k: MultiPoint(list(v)) for k, v in pois_meter.groupby(['kne_idx'])['pp']}\n",
    "    new_lines = [split_line(edges_meter['geometry'][idx], pps) for idx, pps in line_pps_dict.items()]  # bit slow\n",
    "    edges_meter, _ = update_edges(edges_meter, new_lines, replace=True)\n",
    "\n",
    "    ## STAGE 2: connection\n",
    "    # 2-1: update external edges (projected footways connected to pois)\n",
    "    # establish new_edges\n",
    "    print(\"Updating external links...\")\n",
    "    pps_gdf = nodes_meter[nodes_meter['highway'] == node_highway_pp]\n",
    "    new_lines = [LineString([p1, p2]) for p1, p2 in zip(pois_meter['geometry'], pps_gdf['geometry'])]\n",
    "    edges_meter, _ = update_edges(edges_meter, new_lines, replace=False)\n",
    "\n",
    "    ## STAGE 3: output\n",
    "    # convert CRS\n",
    "    nodes = nodes_meter.to_crs(epsg=4326)\n",
    "    edges = edges_meter.to_crs(epsg=4326)\n",
    "\n",
    "    # preprocess for pandana\n",
    "    nodes.index = nodes['osmid']  # IMPORTANT\n",
    "    nodes['x'] = [p.x for p in nodes['geometry']]\n",
    "    nodes['y'] = [p.y for p in nodes['geometry']]\n",
    "\n",
    "    # edges.reset_index(drop=True, inplace=True)\n",
    "    edges['length'] = edges['length'].astype(float)\n",
    "\n",
    "    # report issues\n",
    "    # - examine key duplication\n",
    "    if len(nodes_meter) != len(nodes_id_dict):\n",
    "        print(\"NOTE: duplication in node coordinates keys\")\n",
    "        print(\"Nodes count:\", len(nodes_meter))\n",
    "        print(\"Node coordinates key count:\", len(nodes_id_dict))\n",
    "    # - examine missing nodes\n",
    "    print(\"Missing 'from' nodes:\", len(edges[edges['from'] == None]))\n",
    "    print(\"Missing 'to' nodes:\", len(edges[edges['to'] == None]))\n",
    "\n",
    "    # save and return\n",
    "    if path:\n",
    "        nodes.to_file(path+'/nodes.shp')\n",
    "        edges.to_file(path+'/edges.shp')\n",
    "\n",
    "    return nodes, edges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a399c1-b704-40b7-b514-20cb38601087",
   "metadata": {},
   "source": [
    "The following functions do our algorithm to compute distances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28c5e937-b9df-4751-9ed0-b347820fe161",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining input directories:\n",
    "fua_buffered_shapefile_dir = '../data/d03_intermediate/FUA-buffered-shapefile/'\n",
    "full_od_matrix_dir = '../data/d02_processed-safegraph/'\n",
    "networks_dir = '../data/d03_intermediate/FUA-networks/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b2a025b8-448c-4c5d-bec3-194cf1c0387d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_boundary(fua_code):\n",
    "    return gpd.read_file(fua_buffered_shapefile_dir + 'FUA-buffered.shp').set_index('fuacode').loc[[fua_code]]\n",
    "\n",
    "def get_fua_ODmatrix(fua_code, split_in_half=split):\n",
    "    full_od_matrix = pd.read_csv(full_od_matrix_dir + 'weeks_od_us_fua.csv')\n",
    "    fua_raw_od_matrix = full_od_matrix[full_od_matrix.fuacode==fua_code].reset_index(drop=True)\n",
    "    fua_raw_od_matrix['fuacode'] = fua_code\n",
    "    \n",
    "    if split_in_half == 1:\n",
    "        return fua_raw_od_matrix[:len(fua_raw_od_matrix)//2].reset_index(drop=True)\n",
    "    elif split_in_half == 2:\n",
    "        return fua_raw_od_matrix[len(fua_raw_od_matrix)//2:].reset_index(drop=True)\n",
    "    else:\n",
    "        return fua_raw_od_matrix\n",
    "\n",
    "def load_graphs(fua_code, proj_crs='EPSG:5070'):\n",
    "    walk_graph = ox.project_graph(ox.load_graphml(networks_dir + 'walk/'+fua_code+'.graphml'), to_crs=proj_crs)\n",
    "    drive_graph = ox.project_graph(ox.load_graphml(networks_dir + 'drive/'+fua_code+'.graphml'), to_crs=proj_crs)\n",
    "    \n",
    "    return walk_graph, drive_graph\n",
    "\n",
    "def trim_centroids(od_matrix, buffered_boundary, bdry_as_gdf=True):\n",
    "    \n",
    "    if bdry_as_gdf:\n",
    "        buffered_boundary = buffered_boundary.geometry[0]\n",
    "    \n",
    "    centroids_pt = gpd.points_from_xy(x= od_matrix.intptlon, y=od_matrix.intptlat, crs='EPSG:4326')\n",
    "    rows_to_keep = centroids_pt.within(buffered_boundary)\n",
    "    trimmed_od_matrix = od_matrix[rows_to_keep].reset_index(drop=True)\n",
    "    \n",
    "    print('.   total of', len(trimmed_od_matrix), ' rows')\n",
    "\n",
    "    return trimmed_od_matrix\n",
    "\n",
    "def expand_graph(nodes, edges, centroids, pois):\n",
    "    \n",
    "    centroids_new = gpd.GeoDataFrame(centroids.rename({'census_block_group':'place_id'}, axis=1), crs='EPSG:4326')\n",
    "    pois_new = gpd.GeoDataFrame(pois.rename({'safegraph_place_id':'place_id'}, axis=1), crs='EPSG:4326')\n",
    "    external_nodes = centroids_new.append(pois_new).reset_index(drop=True)\n",
    "    external_nodes['numerical_id'] = external_nodes.index\n",
    "    \n",
    "    expanded_nodes, expanded_edges = connect_poi(external_nodes, nodes, edges, threshold=1000)\n",
    "    \n",
    "    expanded_edges_multi = expanded_edges.set_index(['from','to','key']).rename({'from':'u', 'to':'v'}, axis=1)\n",
    "    \n",
    "    print(expanded_edges.head())\n",
    "    print(expanded_edges_multi.head())\n",
    "    \n",
    "    expanded_graph = ox.utils_graph.graph_from_gdfs(expanded_nodes, expanded_edges_multi)\n",
    "    \n",
    "    return expanded_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c9a3e0-7494-46ca-ae33-d3317b57ad16",
   "metadata": {},
   "source": [
    "Let's test it for a few rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701c149e-e9c1-4c78-a8a9-cd0d27898d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "fua_code = 'USA160'\n",
    "start = datetime.now()\n",
    "\n",
    "#1. LOAD ALL THE FILES:\n",
    "fua_buffered_boundary = get_boundary(fua_code) #get the FUA boundary\n",
    "fua_raw_od_matrix = get_fua_ODmatrix(fua_code) #get the commutes within that FUA\n",
    "fua_od_matrix = trim_centroids(fua_raw_od_matrix, fua_buffered_boundary) #exclude far away centroids\n",
    "walk_graph, drive_graph = load_graphs(fua_code) #get the graphs\n",
    "\n",
    "loading_complete=datetime.now()\n",
    "print(' Loaded all files in:', loading_complete-start)\n",
    "\n",
    "#2. GET THE TWO GEODATAFRAMES TO LINK:\n",
    "centroids_pt = gpd.points_from_xy(x=fua_od_matrix.intptlon, y=fua_od_matrix.intptlat, crs='EPSG:4326')\n",
    "centroids_gdf = gpd.GeoDataFrame(fua_od_matrix[['census_block_group']], geometry=centroids_pt)\n",
    "centroids_gdf.drop_duplicates(subset='census_block_group', keep=False, inplace=True)\n",
    "\n",
    "pois_pt = gpd.points_from_xy(x=fua_od_matrix.longitude, y=fua_od_matrix.latitude, crs='EPSG:4326')\n",
    "pois_gdf = gpd.GeoDataFrame(fua_od_matrix[['safegraph_place_id']], geometry=pois_pt)\n",
    "pois_gdf.drop_duplicates(subset='safegraph_place_id', keep=False, inplace=True)\n",
    "\n",
    "georeferencing_complete=datetime.now()\n",
    "print(' Georeferenced centroids and POIs in:', georeferencing_complete-loading_complete)\n",
    "\n",
    "#3. CONSTRUCT THE NEW GRAPHS:\n",
    "nodes_walk, edges_walk_multi = ox.utils_graph.graph_to_gdfs(walk_graph)\n",
    "edges_walk = edges_walk_multi.reset_index().rename({'u':'from', 'v':'to'}, axis=1)\n",
    "\n",
    "nodes_drive, edges_drive_multi = ox.utils_graph.graph_to_gdfs(drive_graph)\n",
    "edges_drive = edges_drive_multi.reset_index().rename({'u':'from', 'v':'to'}, axis=1)\n",
    "\n",
    "expanded_walk_graph = expand_graph(nodes_walk, edges_walk, centroids_gdf, pois_gdf)\n",
    "expanded_drive_graph = expand_graph(nodes_walk, edges_walk, centroids_gdf, pois_gdf)\n",
    "\n",
    "graph_complete=datetime.now()\n",
    "print(' Expanded graph in:', graph_complete-georeferencing_complete)\n",
    "\n",
    "#4. SAVE:\n",
    "ox.save_graphml(expanded_walk_graph, filepath='/temp/walk/'+fua_code+'.graphml')\n",
    "ox.save_graphml(expanded_drive_graph, filepath='/temp/drive/'+fua_code+'.graphml')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
