{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b590d69-70e9-4547-a9fe-1b942e1d6de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "import osmnx as ox\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8969bc16-ae7a-4a29-b423-f76bea24541c",
   "metadata": {},
   "source": [
    "# Snapping POIs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc9c34e-0f2d-43ab-a8c0-058ed35c8ff3",
   "metadata": {},
   "source": [
    "Following the approach proposed in [this blog post](https://towardsdatascience.com/connecting-pois-to-a-road-network-358a81447944) by Yuwen Chang, we can attach the POIs and centroids to the street networks as new nodes. The modified code is available in the src directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56f3bb01-f081-4c01-a89c-751110fc4507",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "import rtree\n",
    "import itertools\n",
    "\n",
    "from shapely.geometry import MultiPoint, LineString\n",
    "from shapely.ops import snap, split\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "def connect_poi(pois, nodes, edges, key_col=None, path=None, threshold=200, knn=5, meter_epsg=3857):\n",
    "    \"\"\"Connect and integrate a set of POIs into an existing road network.\n",
    "    Given a road network in the form of two GeoDataFrames: nodes and edges,\n",
    "    link each POI to the nearest edge (road segment) based on its projection\n",
    "    point (PP) and generate a new integrated road network including the POIs,\n",
    "    the projected points, and the connection edge.\n",
    "    Args:\n",
    "        pois (GeoDataFrame): a gdf of POI (geom: Point)\n",
    "        nodes (GeoDataFrame): a gdf of road network nodes (geom: Point)\n",
    "        edges (GeoDataFrame): a gdf of road network edges (geom: LineString)\n",
    "        key_col (str): a unique key column of pois should be provided,\n",
    "                       e.g., 'index', 'osmid', 'poi_number', etc.\n",
    "                       Currently, this will be renamed into 'osmid' in the output.\n",
    "                       [NOTE] For use in pandana, you may want to ensure this\n",
    "                              column is numeric-only to avoid processing errors.\n",
    "                              Preferably use unique integers (int or str) only,\n",
    "                              and be aware not to intersect with the node key,\n",
    "                              'osmid' if you use OSM data, in the nodes gdf.\n",
    "        path (str): directory path to use for saving files (nodes and edges).\n",
    "                      Outputs will NOT be saved if this arg is not specified.\n",
    "        threshold (int): the max length of a POI connection edge, POIs with\n",
    "                         connection edge beyond this length will be removed.\n",
    "                         The unit is in meters as crs epsg is set to 3857 by\n",
    "                         default during processing.\n",
    "        knn (int): k nearest neighbors to query for the nearest edge.\n",
    "                   Consider increasing this number up to 10 if the connection\n",
    "                   output is slightly unreasonable. But higher knn number will\n",
    "                   slow down the process.\n",
    "        meter_epsg (int): preferred EPSG in meter units. Suggested 3857 or 3395.\n",
    "    Returns:\n",
    "        nodes (GeoDataFrame): the original gdf with POIs and PPs appended\n",
    "        edges (GeoDataFrame): the original gdf with connection edges appended\n",
    "                              and existing edges updated (if PPs are present)\n",
    "    Note:\n",
    "        1. Make sure all three input GeoDataFrames have defined crs attribute.\n",
    "           Try something like `gdf.crs` or `gdf.crs = 'epsg:4326'`.\n",
    "           They will then be converted into epsg:3857 or specified meter_epsg for processing.\n",
    "    \"\"\"\n",
    "\n",
    "    ## STAGE 0: initialization\n",
    "    # 0-1: helper functions\n",
    "    def find_kne(point, lines):\n",
    "        dists = np.array(list(map(lambda l: l.distance(point), lines)))\n",
    "        kne_pos = dists.argsort()[0]\n",
    "        kne = lines.iloc[[kne_pos]]\n",
    "        kne_idx = kne.index[0]\n",
    "        return kne_idx, kne.values[0]\n",
    "\n",
    "    def get_pp(point, line):\n",
    "        \"\"\"Get the projected point (pp) of 'point' on 'line'.\"\"\"\n",
    "        # project new Point to be interpolated\n",
    "        pp = line.interpolate(line.project(point))  # PP as a Point\n",
    "        return pp\n",
    "\n",
    "    def split_line(line, pps):\n",
    "        \"\"\"Split 'line' by all intersecting 'pps' (as multipoint).\n",
    "        Returns:\n",
    "            new_lines (list): a list of all line segments after the split\n",
    "        \"\"\"\n",
    "        # IMPORTANT FIX for ensuring intersection between splitters and the line\n",
    "        # but no need for updating edges_meter manually because the old lines will be\n",
    "        # replaced anyway\n",
    "        line = snap(line, pps, 1e-8)  # slow?\n",
    "\n",
    "        try:\n",
    "            new_lines = list(split(line, pps))  # split into segments\n",
    "            return new_lines\n",
    "        except TypeError as e:\n",
    "            print('Error when splitting line: {}\\n{}\\n{}\\n'.format(e, line, pps))\n",
    "            return []\n",
    "\n",
    "    def update_nodes(nodes, new_points, ptype, meter_epsg=3857):\n",
    "        \"\"\"Update nodes with a list (pp) or a GeoDataFrame (poi) of new_points.\n",
    "        \n",
    "        Args:\n",
    "            ptype: type of Point list to append, 'pp' or 'poi'\n",
    "        \"\"\"\n",
    "        # create gdf of new nodes (projected PAPs)\n",
    "        if ptype == 'pp':\n",
    "            new_nodes = gpd.GeoDataFrame(new_points, columns=['geometry'], crs=f'epsg:{meter_epsg}')\n",
    "            n = len(new_nodes)\n",
    "            new_nodes['highway'] = node_highway_pp\n",
    "            new_nodes['osmid'] = [int(osmid_prefix + i) for i in range(n)]\n",
    "\n",
    "        # create gdf of new nodes (original POIs)\n",
    "        elif ptype == 'poi':\n",
    "            new_nodes = new_points[['geometry', key_col]]\n",
    "            new_nodes.columns = ['geometry', 'osmid']\n",
    "            new_nodes['highway'] = node_highway_poi\n",
    "            new_nodes['osmid'] = new_nodes['osmid'].astype(int)\n",
    "\n",
    "        else:\n",
    "            print(\"Unknown ptype when updating nodes.\")\n",
    "\n",
    "        # merge new nodes (it is safe to ignore the index for nodes)\n",
    "        gdfs = [nodes, new_nodes]\n",
    "        nodes = gpd.GeoDataFrame(pd.concat(gdfs, ignore_index=True, sort=False),\n",
    "                                 crs=gdfs[0].crs)\n",
    "\n",
    "        return nodes, new_nodes  # all nodes, newly added nodes only\n",
    "\n",
    "    def update_edges(edges, new_lines, replace):\n",
    "        \"\"\"\n",
    "        Update edge info by adding new_lines; or,\n",
    "        replace existing ones with new_lines (n-split segments).\n",
    "        Args:\n",
    "            replace: treat new_lines (flat list) as newly added edges if False,\n",
    "                     else replace existing edges with new_lines (often a nested list)\n",
    "        \n",
    "        Note:\n",
    "            kne_idx refers to 'fid in Rtree'/'label'/'loc', not positional iloc\n",
    "        \"\"\"\n",
    "        # for interpolation (split by pp): replicate old line\n",
    "        if replace:\n",
    "            # create a flattened gdf with all line segs and corresponding kne_idx\n",
    "            kne_idxs = list(line_pps_dict.keys())\n",
    "            lens = [len(item) for item in new_lines]\n",
    "            new_lines_gdf = gpd.GeoDataFrame(\n",
    "                {'kne_idx': np.repeat(kne_idxs, lens),\n",
    "                 'geometry': list(itertools.chain.from_iterable(new_lines))})\n",
    "            # merge to inherit the data of the replaced line\n",
    "            cols = list(edges.columns)\n",
    "            cols.remove('geometry')  # don't include the old geometry\n",
    "            new_edges = new_lines_gdf.merge(edges[cols], how='left', left_on='kne_idx', right_index=True)\n",
    "            new_edges.drop('kne_idx', axis=1, inplace=True)\n",
    "            new_lines = new_edges['geometry']  # now a flatten list\n",
    "        # for connection (to external poi): append new lines\n",
    "        else:\n",
    "            new_edges = gpd.GeoDataFrame(pois[[key_col]], geometry=new_lines, columns=[key_col, 'geometry'])\n",
    "            new_edges['oneway'] = False\n",
    "            new_edges['highway'] = edge_highway\n",
    "\n",
    "        # update features (a bit slow)\n",
    "        new_edges['length'] = [l.length for l in new_lines]\n",
    "        new_edges['from'] = new_edges['geometry'].map(\n",
    "            lambda x: nodes_id_dict.get(list(x.coords)[0], None))\n",
    "        new_edges['to'] = new_edges['geometry'].map(\n",
    "            lambda x: nodes_id_dict.get(list(x.coords)[-1], None))\n",
    "        new_edges['osmid'] = ['_'.join(list(map(str, s))) for s in zip(new_edges['from'], new_edges['to'])]\n",
    "\n",
    "        # remember to reindex to prevent duplication when concat\n",
    "        start = edges.index[-1] + 1\n",
    "        stop = start + len(new_edges)\n",
    "        new_edges.index = range(start, stop)\n",
    "\n",
    "        # for interpolation: remove existing edges\n",
    "        if replace:\n",
    "            edges = edges.drop(kne_idxs, axis=0)\n",
    "        # for connection: filter invalid links\n",
    "        else:\n",
    "            valid_pos = np.where(new_edges['length'] <= threshold)[0]\n",
    "            n = len(new_edges)\n",
    "            n_fault = n - len(valid_pos)\n",
    "            f_pct = n_fault / n * 100\n",
    "            print(\"Remove faulty projections: {}/{} ({:.2f}%)\".format(n_fault, n, f_pct))\n",
    "            new_edges = new_edges.iloc[valid_pos]  # use 'iloc' here\n",
    "\n",
    "        # merge new edges\n",
    "        dfs = [edges, new_edges]\n",
    "        edges = gpd.GeoDataFrame(pd.concat(dfs, ignore_index=False, sort=False), crs=dfs[0].crs)\n",
    "\n",
    "        # all edges, newly added edges only\n",
    "        return edges, new_edges\n",
    "\n",
    "    # 0-2: configurations\n",
    "    # set poi arguments\n",
    "    node_highway_pp = 'projected_pap'  # POI Access Point\n",
    "    node_highway_poi = 'poi'\n",
    "    edge_highway = 'projected_footway'\n",
    "    osmid_prefix = 9990000000\n",
    "\n",
    "    # convert CRS\n",
    "    pois_meter = pois.to_crs(epsg=meter_epsg)\n",
    "    nodes_meter = nodes.to_crs(epsg=meter_epsg)\n",
    "    edges_meter = edges.to_crs(epsg=meter_epsg)\n",
    "\n",
    "    # build rtree\n",
    "    print(\"Building rtree...\")\n",
    "    Rtree = rtree.index.Index()\n",
    "    [Rtree.insert(fid, geom.bounds) for fid, geom in edges_meter['geometry'].iteritems()]\n",
    "\n",
    "    ## STAGE 1: interpolation\n",
    "    # 1-1: update external nodes (pois)\n",
    "    print(\"Updating external nodes...\")\n",
    "    nodes_meter, _ = update_nodes(nodes_meter, pois_meter, ptype='poi', meter_epsg=meter_epsg)\n",
    "\n",
    "    # 1-2: update internal nodes (interpolated pps)\n",
    "    # locate nearest edge (kne) and projected point (pp)\n",
    "    print(\"Projecting POIs to the network...\")\n",
    "    pois_meter['near_idx'] = [list(Rtree.nearest(point.bounds, knn))\n",
    "                              for point in pois_meter['geometry']]  # slow\n",
    "    pois_meter['near_lines'] = [edges_meter['geometry'][near_idx]\n",
    "                                for near_idx in pois_meter['near_idx']]  # very slow\n",
    "    pois_meter['kne_idx'], knes = zip(\n",
    "        *[find_kne(point, near_lines) for point, near_lines in\n",
    "          zip(pois_meter['geometry'], pois_meter['near_lines'])])  # slow\n",
    "    pois_meter['pp'] = [get_pp(point, kne) for point, kne in zip(pois_meter['geometry'], knes)]\n",
    "\n",
    "    # update nodes\n",
    "    print(\"Updating internal nodes...\")\n",
    "    nodes_meter, _ = update_nodes(nodes_meter, list(pois_meter['pp']), ptype='pp', meter_epsg=meter_epsg)\n",
    "    nodes_coord = nodes_meter['geometry'].map(lambda x: x.coords[0])\n",
    "    nodes_id_dict = dict(zip(nodes_coord, nodes_meter['osmid'].astype('Int64')))\n",
    "\n",
    "    # 1-3: update internal edges (split line segments)\n",
    "    print(\"Updating internal edges...\")\n",
    "    # split\n",
    "    line_pps_dict = {k: MultiPoint(list(v)) for k, v in pois_meter.groupby(['kne_idx'])['pp']}\n",
    "    new_lines = [split_line(edges_meter['geometry'][idx], pps) for idx, pps in line_pps_dict.items()]  # bit slow\n",
    "    edges_meter, _ = update_edges(edges_meter, new_lines, replace=True)\n",
    "\n",
    "    ## STAGE 2: connection\n",
    "    # 2-1: update external edges (projected footways connected to pois)\n",
    "    # establish new_edges\n",
    "    print(\"Updating external links...\")\n",
    "    pps_gdf = nodes_meter[nodes_meter['highway'] == node_highway_pp]\n",
    "    new_lines = [LineString([p1, p2]) for p1, p2 in zip(pois_meter['geometry'], pps_gdf['geometry'])]\n",
    "    edges_meter, _ = update_edges(edges_meter, new_lines, replace=False)\n",
    "\n",
    "    ## STAGE 3: output\n",
    "    # convert CRS\n",
    "    nodes = nodes_meter.to_crs(epsg=4326)\n",
    "    edges = edges_meter.to_crs(epsg=4326)\n",
    "\n",
    "    # preprocess for pandana\n",
    "    nodes.index = nodes['osmid']  # IMPORTANT\n",
    "    nodes['x'] = [p.x for p in nodes['geometry']]\n",
    "    nodes['y'] = [p.y for p in nodes['geometry']]\n",
    "\n",
    "    # edges.reset_index(drop=True, inplace=True)\n",
    "    edges['length'] = edges['length'].astype(float)\n",
    "\n",
    "    # report issues\n",
    "    # - examine key duplication\n",
    "    if len(nodes_meter) != len(nodes_id_dict):\n",
    "        print(\"NOTE: duplication in node coordinates keys\")\n",
    "        print(\"Nodes count:\", len(nodes_meter))\n",
    "        print(\"Node coordinates key count:\", len(nodes_id_dict))\n",
    "    # - examine missing nodes\n",
    "    print(\"Missing 'from' nodes:\", len(edges[edges['from'] == None]))\n",
    "    print(\"Missing 'to' nodes:\", len(edges[edges['to'] == None]))\n",
    "\n",
    "    # save and return\n",
    "    if path:\n",
    "        nodes.to_file(path+'/nodes.shp')\n",
    "        edges.to_file(path+'/edges.shp')\n",
    "\n",
    "    return nodes, edges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a399c1-b704-40b7-b514-20cb38601087",
   "metadata": {},
   "source": [
    "The following functions do our algorithm to compute distances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a025b8-448c-4c5d-bec3-194cf1c0387d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fua_buffered_shapefile_dir = '../data/d03_intermediate/FUA-buffered-shapefile/'\n",
    "full_od_matrix_dir = '../data/d02_processed-safegraph/'\n",
    "networks_dir = '../data/d03_intermediate/FUA-networks/'\n",
    "\n",
    "def get_boundary(fua_code):\n",
    "    return gpd.read_file(fua_buffered_shapefile_dir + 'FUA-buffered.shp').set_index('fuacode').loc[[fua_code]]\n",
    "\n",
    "def get_fua_ODmatrix(fua_code):\n",
    "    full_od_matrix = pd.read_csv(full_od_matrix_dir + 'weeks_od_us_fua.csv', nrows=1000)\n",
    "    fua_raw_od_matrix = full_od_matrix[full_od_matrix.fuacode==fua_code][:10].reset_index(drop=True)\n",
    "    fua_raw_od_matrix['fuacode'] = fua_code\n",
    "    \n",
    "    return fua_raw_od_matrix\n",
    "\n",
    "def load_graphs(fua_code, proj_crs='EPSG:5070'):\n",
    "    walk_graph = ox.project_graph(ox.load_graphml(networks_dir + 'walk/'+fua_code+'.graphml'), to_crs=proj_crs)\n",
    "    drive_graph = ox.project_graph(ox.load_graphml(networks_dir + 'drive/'+fua_code+'.graphml'), to_crs=proj_crs)\n",
    "    \n",
    "    return walk_graph, drive_graph\n",
    "\n",
    "def trim_centroids(od_matrix, buffered_boundary, bdry_as_gdf=True):\n",
    "    \n",
    "    if bdry_as_gdf:\n",
    "        buffered_boundary = buffered_boundary.geometry[0]\n",
    "    \n",
    "    centroids_pt = gpd.points_from_xy(x= od_matrix.intptlon, y=od_matrix.intptlat, crs='EPSG:4326')\n",
    "    rows_to_keep = centroids_pt.within(buffered_boundary)\n",
    "    trimmed_od_matrix = od_matrix[rows_to_keep].reset_index(drop=True)\n",
    "    \n",
    "    print('.   total of', len(trimmed_od_matrix), ' rows')\n",
    "\n",
    "    return trimmed_od_matrix\n",
    "\n",
    "def add_od_geometries(od_matrix, proj_crs='EPSG:5070'):\n",
    "    centroids_pt = gpd.points_from_xy(x=od_matrix.intptlon, y=od_matrix.intptlat, crs='EPSG:4326').to_crs(proj_crs)\n",
    "    od_matrix['origin_x'], od_matrix['origin_y'] = centroids_pt.x, centroids_pt.y\n",
    "\n",
    "    places_pt = gpd.points_from_xy(x= od_matrix.longitude, y=od_matrix.latitude, crs='EPSG:4326').to_crs(proj_crs)\n",
    "    od_matrix['dest_x'], od_matrix['dest_y'] = places_pt.x, places_pt.y\n",
    "    \n",
    "    return od_matrix\n",
    "\n",
    "def add_preferred_mode(od_matrix, max_walk_dist=2000, proj_crs='EPSG:5070'):\n",
    "    \n",
    "    places_pt = gpd.points_from_xy(x= od_matrix.longitude, y=od_matrix.latitude, crs='EPSG:4326').to_crs(proj_crs)\n",
    "    centroids_pt = gpd.points_from_xy(x=od_matrix.intptlon, y=od_matrix.intptlat, crs='EPSG:4326').to_crs(proj_crs)\n",
    "    \n",
    "    od_matrix['mode'] = places_pt.distance(centroids_pt) <= max_walk_dist\n",
    "    od_matrix['mode'] = od_matrix['mode'].map({True: 'walk', False:'drive'})\n",
    "    \n",
    "    return od_matrix\n",
    "    \n",
    "def add_distances(od_matrix, walk_graph, drive_graph, cpus=1):\n",
    "    \n",
    "    #Split the dataframe in two according to commute mode:\n",
    "    od_matrix_dict = {mode: df for mode, df in od_matrix.groupby('mode')}\n",
    "    G = {'drive': drive_graph, 'walk': walk_graph}\n",
    "    \n",
    "    #For each of the commute modes, do the distance computation:\n",
    "    full_dfs = []\n",
    "    for mode, df in od_matrix_dict.items():\n",
    "        df['distance'] = parallel_shortest_path_taxicab_distance(G[mode],\n",
    "                                                                 zip(df['origin_y'].values, df['origin_x'].values),\n",
    "                                                                 zip(df['dest_y'].values, df['dest_x'].values),\n",
    "                                                                 cpus)\n",
    "        full_dfs.append(df)    \n",
    "    \n",
    "    #Merge the two dataframes:\n",
    "    od_matrix_naivedistance = pd.concat(full_dfs, ignore_index=True)\n",
    "    \n",
    "    return od_matrix_naivedistance\n",
    "\n",
    "def refine_distances(od_matrix_with_distances, drive_graph, max_walk_dist=2000, cpus=1):\n",
    "    \n",
    "    rows_to_repeat = (od_matrix_with_distances['mode']=='walk') & (od_matrix_with_distances['distance'] > max_walk_dist)\n",
    "    df_to_repeat = od_matrix_with_distances[rows_to_repeat]\n",
    "    \n",
    "    print('.   repeat for', len(df_to_repeat), ' rows')\n",
    "    \n",
    "    if len(df_to_repeat) > 0:\n",
    "        origin_yx = zip(df_to_repeat['origin_y'].values, df_to_repeat['origin_x'].values)\n",
    "        dest_yx = zip(df_to_repeat['dest_y'].values, df_to_repeat['dest_x'].values)\n",
    "\n",
    "        od_matrix_with_distances.loc[rows_to_repeat, 'distance'] = parallel_shortest_path_taxicab_distance(drive_graph,\n",
    "                                                                                                           origin_yx, dest_yx,\n",
    "                                                                                                           cpus)\n",
    "    \n",
    "    return od_matrix_with_distances\n",
    "\n",
    "def drop_cols(od_matrix, cols_to_drop=['origin_x', 'origin_y', 'dest_x', 'dest_y']):\n",
    "    \n",
    "    for col in od_matrix_naivedistance.columns:\n",
    "        if 'Unnamed' in col:\n",
    "            cols_to_drop.append(col)\n",
    "            \n",
    "    final_matrix = od_matrix.drop(cols_to_drop, axis=1).reset_index(drop=True)\n",
    "    \n",
    "    return final_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c9a3e0-7494-46ca-ae33-d3317b57ad16",
   "metadata": {},
   "source": [
    "Let's test it for a few rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d59972-09f4-4bbb-863f-ebd28e4f8a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold=2000\n",
    "number_of_cores=2\n",
    "fua_code='USA80'\n",
    "\n",
    "start=datetime.now()\n",
    "\n",
    "#1. LOAD ALL THE FILES:\n",
    "fua_buffered_boundary = get_boundary(fua_code) #get the FUA boundary\n",
    "fua_raw_od_matrix = get_fua_ODmatrix(fua_code) #get the commutes within that FUA\n",
    "walk_graph, drive_graph = load_graphs(fua_code) #get the graphs\n",
    "\n",
    "loading_complete=datetime.now()\n",
    "print('Loaded all files in:', loading_complete-start)\n",
    "\n",
    "#2. PREPROCESS THE MATRIX:\n",
    "fua_od_matrix = trim_centroids(fua_raw_od_matrix, fua_buffered_boundary)\n",
    "georeferenced_fua_od_matrix = add_od_geometries(fua_od_matrix)\n",
    "georeferenced_fua_od_matrix_with_mode = add_preferred_mode(georeferenced_fua_od_matrix, threshold)\n",
    "\n",
    "processing_complete=datetime.now()\n",
    "print('Prepared matrix in:', processing_complete-loading_complete)\n",
    "\n",
    "#3. OBTAIN THE DISTANCES:\n",
    "matrix_naive_distances = add_distances(georeferenced_fua_od_matrix_with_mode, walk_graph, drive_graph, cpus=number_of_cores)\n",
    "\n",
    "distances_complete=datetime.now()\n",
    "print('Obtained distances in:', distances_complete-processing_complete)\n",
    "\n",
    "#4. REPEAT FOR EDGE CASES:\n",
    "matrix_final_distances = refine_distances(matrix_naive_distances, drive_graph, threshold, cpus=number_of_cores)\n",
    "\n",
    "all_complete=datetime.now()\n",
    "print('Refined distances in:', all_complete-distances_complete)\n",
    "\n",
    "#5. WRAP-UP MATRIX AND SAVE IT:\n",
    "final_matrix = drop_cols(matrix_final_distances)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
